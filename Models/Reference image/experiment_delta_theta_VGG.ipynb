{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment delta_theta VGG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5mcsngV9IjX",
        "outputId": "7eacc33d-5f8a-48c9-c998-36dbbd124cba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aClCGALS9N6c",
        "outputId": "4b9cdaf2-4576-44e0-be17-40ecaee0e7a7"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive')\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_YleJ_xiBkd",
        "outputId": "e1e8e23a-e98d-47dd-a776-c0f9bab9e724"
      },
      "source": [
        "%tensorflow_version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently selected TF version: 2.x\n",
            "Available versions:\n",
            "* 1.x\n",
            "* 2.x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUAVH2STVC_U"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation, concatenate\n",
        "from keras.layers.advanced_activations import ReLU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import random\n",
        "import math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TAoFO4R-jOC"
      },
      "source": [
        "def load_dataset():\n",
        "  train_data = pd.read_csv('trainset.csv')\n",
        "  y_train = pd.read_csv('delta_theta.csv')\n",
        "  target_data = pd.read_csv('target_data.csv')\n",
        "  # target_label = pd.read_csv('target_label.csv')\n",
        "  return train_data, y_train, target_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJwQAkT2-zkv"
      },
      "source": [
        "# train_data.head()\n",
        "# y_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy57sGOsBdNh"
      },
      "source": [
        "train_data, y_train, target_data = load_dataset()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmppeSVB_BRm"
      },
      "source": [
        "# train_data.shape\n",
        "# target_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfuJXir7E1-k"
      },
      "source": [
        "num_classes = 4\n",
        "train_data = np.array(train_data.iloc[:,:])\n",
        "train_data = np.array([np.reshape(i,(128,128)) for i in train_data])\n",
        "target_data = np.array(target_data.iloc[:,:])\n",
        "target_data = np.array([np.reshape(i,(128,128)) for i in target_data])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w02tvuvtE5k_",
        "outputId": "40751f5d-7571-4a33-83df-b314082962aa"
      },
      "source": [
        "train_data.shape\n",
        "target_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(333, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaXR-fhI1TMc",
        "outputId": "df01b311-e80e-4e77-e8b1-4515661a180d"
      },
      "source": [
        "train_data = train_data.astype('float32')\n",
        "train_data = train_data/255\n",
        "\n",
        "rgb_batch = np.repeat(train_data[..., np.newaxis], 3, -1)\n",
        "rgb_batch.shape\n",
        "\n",
        "target_data = target_data.astype('float32')\n",
        "target_data = target_data/255\n",
        "\n",
        "rgb_target = np.repeat(target_data[..., np.newaxis], 3, -1)\n",
        "rgb_target.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(333, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8QTLdM0QeBr"
      },
      "source": [
        "target_data = rgb_target"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWPUCq7qhC3N",
        "outputId": "1fb4a952-cf34-4412-9923-675a9a7eecbf"
      },
      "source": [
        "target_data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(333, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3J9DPmoEonU"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(rgb_batch, y_train, test_size = 0.3, random_state=666)\n",
        "target_xtrain, target_xtest = train_test_split(target_data, test_size = 0.3, random_state=666)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEYix5VfIEhe"
      },
      "source": [
        "input_shape = (128, 128, 3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yKRdRCEagQy"
      },
      "source": [
        "# print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlmvUKDGMzlZ"
      },
      "source": [
        "def VGG_16(input_image):\n",
        "    model = Conv2D(64, (3,3), padding=\"same\", input_shape = input_shape)(input_image)\n",
        "    model = ReLU(max_value=1.0)(model)\n",
        "    # model = Conv2D(64, (3,3), padding=\"same\")(model)\n",
        "    # model = ReLU(max_value=1.0)(model)\n",
        "    model = MaxPooling2D(pool_size=(2,2), padding=\"same\")(model)\n",
        "    # model = Dropout(0.25)(model)\n",
        "\n",
        "    model = Conv2D(128, (3,3), padding=\"same\")(model)\n",
        "    model = ReLU(max_value=1.0)(model)\n",
        "    # model = Conv2D(128, (3,3), padding=\"same\")(model)\n",
        "    # model = ReLU(max_value=1.0)(model)\n",
        "    model = MaxPooling2D(pool_size=(2,2), padding=\"same\")(model)\n",
        "    # model = Dropout(0.25)(model)\n",
        "\n",
        "    # model = Conv2D(256, (3,3), padding=\"same\")(model)\n",
        "    # model = ReLU(max_value=1.0)(model)\n",
        "    model = Conv2D(256, (3,3), padding=\"same\")(model)\n",
        "    model = ReLU(max_value=1.0)(model)\n",
        "    model = MaxPooling2D(pool_size=(2,2), padding=\"same\")(model)\n",
        "    model = Dropout(0.25)(model)\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyD2K2hs47BT"
      },
      "source": [
        "current_input = Input(shape=input_shape)\n",
        "current_model = VGG_16(current_input)\n",
        "\n",
        "target_input = Input(shape=input_shape)\n",
        "target_model = VGG_16(target_input)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGY8OydFTU8E"
      },
      "source": [
        "conv = concatenate([current_model, target_model])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjgFVGD1Ta_N"
      },
      "source": [
        "conv = Flatten()(conv)\n",
        "dense = Dense(512)(conv)\n",
        "dense = ReLU(max_value=None)(dense)\n",
        "dense = Dropout(0.5)(dense)\n",
        "# dense = Dense(512)(dense)\n",
        "# dense = ReLU(max_value=1.0)(dense)\n",
        "# dense = Dropout(0.5)(dense)\n",
        "\n",
        "output = Dense(num_classes, activation='linear')(dense)\n",
        "# output = math.floor(output)\n",
        "model = Model(inputs=[current_input, target_input], outputs=[output])\n",
        "\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mse'])\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rHsTXpiU4Zw"
      },
      "source": [
        "best_weights_file=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(best_weights_file, monitor='val_mse', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks = [checkpoint]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LLcG_DpWKp7",
        "outputId": "424eb70d-7a4c-40f5-cfc8-c370811a2575"
      },
      "source": [
        "model.fit([x_train, target_xtrain], y_train,\n",
        "          epochs=100,\n",
        "          validation_split=0.3,\n",
        "          callbacks = callbacks,\n",
        "          verbose=1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 136.3442 - mse: 136.3442 - val_loss: 189.2971 - val_mse: 189.2971\n",
            "\n",
            "Epoch 00001: val_mse improved from -inf to 189.29710, saving model to weights.best.hdf5\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 124.8706 - mse: 124.8706 - val_loss: 190.8282 - val_mse: 190.8282\n",
            "\n",
            "Epoch 00002: val_mse improved from 189.29710 to 190.82817, saving model to weights.best.hdf5\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 112.2422 - mse: 112.2422 - val_loss: 186.3265 - val_mse: 186.3265\n",
            "\n",
            "Epoch 00003: val_mse did not improve from 190.82817\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 104.6768 - mse: 104.6768 - val_loss: 182.1214 - val_mse: 182.1214\n",
            "\n",
            "Epoch 00004: val_mse did not improve from 190.82817\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 96.1294 - mse: 96.1294 - val_loss: 183.5373 - val_mse: 183.5373\n",
            "\n",
            "Epoch 00005: val_mse did not improve from 190.82817\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 89.0383 - mse: 89.0383 - val_loss: 185.8058 - val_mse: 185.8058\n",
            "\n",
            "Epoch 00006: val_mse did not improve from 190.82817\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 85.8276 - mse: 85.8276 - val_loss: 188.3477 - val_mse: 188.3477\n",
            "\n",
            "Epoch 00007: val_mse did not improve from 190.82817\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 79.5910 - mse: 79.5910 - val_loss: 189.0406 - val_mse: 189.0406\n",
            "\n",
            "Epoch 00008: val_mse did not improve from 190.82817\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 78.6885 - mse: 78.6885 - val_loss: 193.0642 - val_mse: 193.0642\n",
            "\n",
            "Epoch 00009: val_mse improved from 190.82817 to 193.06421, saving model to weights.best.hdf5\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 74.7421 - mse: 74.7421 - val_loss: 185.2863 - val_mse: 185.2863\n",
            "\n",
            "Epoch 00010: val_mse did not improve from 193.06421\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 75.5297 - mse: 75.5297 - val_loss: 183.8412 - val_mse: 183.8412\n",
            "\n",
            "Epoch 00011: val_mse did not improve from 193.06421\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 68.3943 - mse: 68.3943 - val_loss: 194.8049 - val_mse: 194.8049\n",
            "\n",
            "Epoch 00012: val_mse improved from 193.06421 to 194.80493, saving model to weights.best.hdf5\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 63.7080 - mse: 63.7080 - val_loss: 189.7543 - val_mse: 189.7543\n",
            "\n",
            "Epoch 00013: val_mse did not improve from 194.80493\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 60.9571 - mse: 60.9571 - val_loss: 188.2297 - val_mse: 188.2297\n",
            "\n",
            "Epoch 00014: val_mse did not improve from 194.80493\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 1s 115ms/step - loss: 57.6924 - mse: 57.6924 - val_loss: 191.2486 - val_mse: 191.2486\n",
            "\n",
            "Epoch 00015: val_mse did not improve from 194.80493\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 52.9689 - mse: 52.9689 - val_loss: 192.3653 - val_mse: 192.3653\n",
            "\n",
            "Epoch 00016: val_mse did not improve from 194.80493\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 53.6685 - mse: 53.6685 - val_loss: 190.5753 - val_mse: 190.5753\n",
            "\n",
            "Epoch 00017: val_mse did not improve from 194.80493\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 52.5415 - mse: 52.5415 - val_loss: 192.5442 - val_mse: 192.5442\n",
            "\n",
            "Epoch 00018: val_mse did not improve from 194.80493\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 50.4345 - mse: 50.4345 - val_loss: 194.0592 - val_mse: 194.0592\n",
            "\n",
            "Epoch 00019: val_mse did not improve from 194.80493\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 48.1589 - mse: 48.1589 - val_loss: 192.0195 - val_mse: 192.0195\n",
            "\n",
            "Epoch 00020: val_mse did not improve from 194.80493\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 46.5214 - mse: 46.5214 - val_loss: 195.3783 - val_mse: 195.3783\n",
            "\n",
            "Epoch 00021: val_mse improved from 194.80493 to 195.37831, saving model to weights.best.hdf5\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 47.3516 - mse: 47.3516 - val_loss: 197.1248 - val_mse: 197.1248\n",
            "\n",
            "Epoch 00022: val_mse improved from 195.37831 to 197.12479, saving model to weights.best.hdf5\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 39.6239 - mse: 39.6239 - val_loss: 190.1148 - val_mse: 190.1148\n",
            "\n",
            "Epoch 00023: val_mse did not improve from 197.12479\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 43.3232 - mse: 43.3232 - val_loss: 192.8489 - val_mse: 192.8489\n",
            "\n",
            "Epoch 00024: val_mse did not improve from 197.12479\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 39.5789 - mse: 39.5789 - val_loss: 201.7116 - val_mse: 201.7116\n",
            "\n",
            "Epoch 00025: val_mse improved from 197.12479 to 201.71161, saving model to weights.best.hdf5\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 40.7164 - mse: 40.7164 - val_loss: 193.7349 - val_mse: 193.7349\n",
            "\n",
            "Epoch 00026: val_mse did not improve from 201.71161\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 37.8535 - mse: 37.8535 - val_loss: 191.9968 - val_mse: 191.9968\n",
            "\n",
            "Epoch 00027: val_mse did not improve from 201.71161\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 36.5917 - mse: 36.5917 - val_loss: 198.8890 - val_mse: 198.8890\n",
            "\n",
            "Epoch 00028: val_mse did not improve from 201.71161\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 37.2317 - mse: 37.2317 - val_loss: 193.0293 - val_mse: 193.0293\n",
            "\n",
            "Epoch 00029: val_mse did not improve from 201.71161\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 34.5737 - mse: 34.5737 - val_loss: 189.9700 - val_mse: 189.9700\n",
            "\n",
            "Epoch 00030: val_mse did not improve from 201.71161\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 35.9120 - mse: 35.9120 - val_loss: 196.7267 - val_mse: 196.7267\n",
            "\n",
            "Epoch 00031: val_mse did not improve from 201.71161\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 32.3835 - mse: 32.3835 - val_loss: 195.2637 - val_mse: 195.2637\n",
            "\n",
            "Epoch 00032: val_mse did not improve from 201.71161\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 32.6595 - mse: 32.6595 - val_loss: 198.4285 - val_mse: 198.4285\n",
            "\n",
            "Epoch 00033: val_mse did not improve from 201.71161\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 33.2205 - mse: 33.2205 - val_loss: 194.5529 - val_mse: 194.5529\n",
            "\n",
            "Epoch 00034: val_mse did not improve from 201.71161\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 32.4418 - mse: 32.4418 - val_loss: 196.6390 - val_mse: 196.6390\n",
            "\n",
            "Epoch 00035: val_mse did not improve from 201.71161\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 29.8125 - mse: 29.8125 - val_loss: 202.6647 - val_mse: 202.6647\n",
            "\n",
            "Epoch 00036: val_mse improved from 201.71161 to 202.66466, saving model to weights.best.hdf5\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 32.3734 - mse: 32.3734 - val_loss: 194.3257 - val_mse: 194.3257\n",
            "\n",
            "Epoch 00037: val_mse did not improve from 202.66466\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 29.6673 - mse: 29.6673 - val_loss: 190.7253 - val_mse: 190.7253\n",
            "\n",
            "Epoch 00038: val_mse did not improve from 202.66466\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 30.9259 - mse: 30.9259 - val_loss: 195.6171 - val_mse: 195.6171\n",
            "\n",
            "Epoch 00039: val_mse did not improve from 202.66466\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 28.1864 - mse: 28.1864 - val_loss: 194.6489 - val_mse: 194.6489\n",
            "\n",
            "Epoch 00040: val_mse did not improve from 202.66466\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 28.0119 - mse: 28.0119 - val_loss: 194.5010 - val_mse: 194.5010\n",
            "\n",
            "Epoch 00041: val_mse did not improve from 202.66466\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 29.7508 - mse: 29.7508 - val_loss: 196.8594 - val_mse: 196.8594\n",
            "\n",
            "Epoch 00042: val_mse did not improve from 202.66466\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 26.6210 - mse: 26.6210 - val_loss: 186.9328 - val_mse: 186.9328\n",
            "\n",
            "Epoch 00043: val_mse did not improve from 202.66466\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 26.4300 - mse: 26.4300 - val_loss: 200.5020 - val_mse: 200.5020\n",
            "\n",
            "Epoch 00044: val_mse did not improve from 202.66466\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 27.2879 - mse: 27.2879 - val_loss: 201.5953 - val_mse: 201.5953\n",
            "\n",
            "Epoch 00045: val_mse did not improve from 202.66466\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 26.2081 - mse: 26.2081 - val_loss: 193.7043 - val_mse: 193.7043\n",
            "\n",
            "Epoch 00046: val_mse did not improve from 202.66466\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 24.2792 - mse: 24.2792 - val_loss: 193.7498 - val_mse: 193.7498\n",
            "\n",
            "Epoch 00047: val_mse did not improve from 202.66466\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 23.8264 - mse: 23.8264 - val_loss: 194.1425 - val_mse: 194.1425\n",
            "\n",
            "Epoch 00048: val_mse did not improve from 202.66466\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 22.9529 - mse: 22.9529 - val_loss: 195.0359 - val_mse: 195.0359\n",
            "\n",
            "Epoch 00049: val_mse did not improve from 202.66466\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 22.1966 - mse: 22.1966 - val_loss: 199.1203 - val_mse: 199.1203\n",
            "\n",
            "Epoch 00050: val_mse did not improve from 202.66466\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 20.9523 - mse: 20.9523 - val_loss: 196.0318 - val_mse: 196.0318\n",
            "\n",
            "Epoch 00051: val_mse did not improve from 202.66466\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 20.4914 - mse: 20.4914 - val_loss: 194.9887 - val_mse: 194.9887\n",
            "\n",
            "Epoch 00052: val_mse did not improve from 202.66466\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 20.6765 - mse: 20.6765 - val_loss: 195.9203 - val_mse: 195.9203\n",
            "\n",
            "Epoch 00053: val_mse did not improve from 202.66466\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 19.2450 - mse: 19.2450 - val_loss: 196.0439 - val_mse: 196.0439\n",
            "\n",
            "Epoch 00054: val_mse did not improve from 202.66466\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 22.7799 - mse: 22.7799 - val_loss: 197.1067 - val_mse: 197.1067\n",
            "\n",
            "Epoch 00055: val_mse did not improve from 202.66466\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 19.6817 - mse: 19.6817 - val_loss: 193.9459 - val_mse: 193.9459\n",
            "\n",
            "Epoch 00056: val_mse did not improve from 202.66466\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 20.3685 - mse: 20.3685 - val_loss: 193.9003 - val_mse: 193.9003\n",
            "\n",
            "Epoch 00057: val_mse did not improve from 202.66466\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 18.9946 - mse: 18.9946 - val_loss: 199.4460 - val_mse: 199.4460\n",
            "\n",
            "Epoch 00058: val_mse did not improve from 202.66466\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 18.4635 - mse: 18.4635 - val_loss: 195.2329 - val_mse: 195.2329\n",
            "\n",
            "Epoch 00059: val_mse did not improve from 202.66466\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 19.0586 - mse: 19.0586 - val_loss: 198.8223 - val_mse: 198.8223\n",
            "\n",
            "Epoch 00060: val_mse did not improve from 202.66466\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 17.0216 - mse: 17.0216 - val_loss: 196.7516 - val_mse: 196.7516\n",
            "\n",
            "Epoch 00061: val_mse did not improve from 202.66466\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 18.3270 - mse: 18.3270 - val_loss: 198.1303 - val_mse: 198.1303\n",
            "\n",
            "Epoch 00062: val_mse did not improve from 202.66466\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 17.6823 - mse: 17.6823 - val_loss: 196.7395 - val_mse: 196.7395\n",
            "\n",
            "Epoch 00063: val_mse did not improve from 202.66466\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 18.9060 - mse: 18.9060 - val_loss: 199.2283 - val_mse: 199.2283\n",
            "\n",
            "Epoch 00064: val_mse did not improve from 202.66466\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 16.9496 - mse: 16.9496 - val_loss: 193.4756 - val_mse: 193.4756\n",
            "\n",
            "Epoch 00065: val_mse did not improve from 202.66466\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 16.2303 - mse: 16.2303 - val_loss: 196.5656 - val_mse: 196.5656\n",
            "\n",
            "Epoch 00066: val_mse did not improve from 202.66466\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 17.8293 - mse: 17.8293 - val_loss: 193.5938 - val_mse: 193.5938\n",
            "\n",
            "Epoch 00067: val_mse did not improve from 202.66466\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 16.8040 - mse: 16.8040 - val_loss: 195.1831 - val_mse: 195.1831\n",
            "\n",
            "Epoch 00068: val_mse did not improve from 202.66466\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 15.6033 - mse: 15.6033 - val_loss: 200.4428 - val_mse: 200.4428\n",
            "\n",
            "Epoch 00069: val_mse did not improve from 202.66466\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 14.9858 - mse: 14.9858 - val_loss: 197.2818 - val_mse: 197.2818\n",
            "\n",
            "Epoch 00070: val_mse did not improve from 202.66466\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 14.8552 - mse: 14.8552 - val_loss: 200.4696 - val_mse: 200.4696\n",
            "\n",
            "Epoch 00071: val_mse did not improve from 202.66466\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 15.6831 - mse: 15.6831 - val_loss: 196.5599 - val_mse: 196.5599\n",
            "\n",
            "Epoch 00072: val_mse did not improve from 202.66466\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 15.9237 - mse: 15.9237 - val_loss: 196.8354 - val_mse: 196.8354\n",
            "\n",
            "Epoch 00073: val_mse did not improve from 202.66466\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 14.4508 - mse: 14.4508 - val_loss: 206.0961 - val_mse: 206.0961\n",
            "\n",
            "Epoch 00074: val_mse improved from 202.66466 to 206.09613, saving model to weights.best.hdf5\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 15.7129 - mse: 15.7129 - val_loss: 196.7523 - val_mse: 196.7523\n",
            "\n",
            "Epoch 00075: val_mse did not improve from 206.09613\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 15.7845 - mse: 15.7845 - val_loss: 196.3496 - val_mse: 196.3496\n",
            "\n",
            "Epoch 00076: val_mse did not improve from 206.09613\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 17.4185 - mse: 17.4185 - val_loss: 202.4217 - val_mse: 202.4217\n",
            "\n",
            "Epoch 00077: val_mse did not improve from 206.09613\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 14.5720 - mse: 14.5720 - val_loss: 194.4001 - val_mse: 194.4001\n",
            "\n",
            "Epoch 00078: val_mse did not improve from 206.09613\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 14.8490 - mse: 14.8490 - val_loss: 199.3909 - val_mse: 199.3909\n",
            "\n",
            "Epoch 00079: val_mse did not improve from 206.09613\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 13.5637 - mse: 13.5637 - val_loss: 201.1137 - val_mse: 201.1137\n",
            "\n",
            "Epoch 00080: val_mse did not improve from 206.09613\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 13.6089 - mse: 13.6089 - val_loss: 198.2354 - val_mse: 198.2354\n",
            "\n",
            "Epoch 00081: val_mse did not improve from 206.09613\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 13.9592 - mse: 13.9592 - val_loss: 199.3163 - val_mse: 199.3163\n",
            "\n",
            "Epoch 00082: val_mse did not improve from 206.09613\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 13.0867 - mse: 13.0867 - val_loss: 198.8126 - val_mse: 198.8126\n",
            "\n",
            "Epoch 00083: val_mse did not improve from 206.09613\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 12.6455 - mse: 12.6455 - val_loss: 200.3454 - val_mse: 200.3454\n",
            "\n",
            "Epoch 00084: val_mse did not improve from 206.09613\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 11.5637 - mse: 11.5637 - val_loss: 199.0486 - val_mse: 199.0486\n",
            "\n",
            "Epoch 00085: val_mse did not improve from 206.09613\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 11.6680 - mse: 11.6680 - val_loss: 195.7566 - val_mse: 195.7566\n",
            "\n",
            "Epoch 00086: val_mse did not improve from 206.09613\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 14.7641 - mse: 14.7641 - val_loss: 198.2873 - val_mse: 198.2873\n",
            "\n",
            "Epoch 00087: val_mse did not improve from 206.09613\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 13.5456 - mse: 13.5456 - val_loss: 203.4202 - val_mse: 203.4202\n",
            "\n",
            "Epoch 00088: val_mse did not improve from 206.09613\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 13.2154 - mse: 13.2154 - val_loss: 195.4690 - val_mse: 195.4690\n",
            "\n",
            "Epoch 00089: val_mse did not improve from 206.09613\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 13.4659 - mse: 13.4659 - val_loss: 196.5553 - val_mse: 196.5553\n",
            "\n",
            "Epoch 00090: val_mse did not improve from 206.09613\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 12.1349 - mse: 12.1349 - val_loss: 195.8183 - val_mse: 195.8183\n",
            "\n",
            "Epoch 00091: val_mse did not improve from 206.09613\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 13.6571 - mse: 13.6571 - val_loss: 204.1787 - val_mse: 204.1787\n",
            "\n",
            "Epoch 00092: val_mse did not improve from 206.09613\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 12.5207 - mse: 12.5207 - val_loss: 197.8062 - val_mse: 197.8062\n",
            "\n",
            "Epoch 00093: val_mse did not improve from 206.09613\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 13.8168 - mse: 13.8168 - val_loss: 200.1593 - val_mse: 200.1593\n",
            "\n",
            "Epoch 00094: val_mse did not improve from 206.09613\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 11.8303 - mse: 11.8303 - val_loss: 198.3706 - val_mse: 198.3706\n",
            "\n",
            "Epoch 00095: val_mse did not improve from 206.09613\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 10.8881 - mse: 10.8881 - val_loss: 201.5651 - val_mse: 201.5651\n",
            "\n",
            "Epoch 00096: val_mse did not improve from 206.09613\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 11.5205 - mse: 11.5205 - val_loss: 196.6856 - val_mse: 196.6856\n",
            "\n",
            "Epoch 00097: val_mse did not improve from 206.09613\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 11.5562 - mse: 11.5562 - val_loss: 198.1775 - val_mse: 198.1775\n",
            "\n",
            "Epoch 00098: val_mse did not improve from 206.09613\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 10.7893 - mse: 10.7893 - val_loss: 198.8397 - val_mse: 198.8397\n",
            "\n",
            "Epoch 00099: val_mse did not improve from 206.09613\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 10.6703 - mse: 10.6703 - val_loss: 196.6208 - val_mse: 196.6208\n",
            "\n",
            "Epoch 00100: val_mse did not improve from 206.09613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd8f79ccc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc_R1cBMXEOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5010970f-0024-4b4e-d122-5093a1ff81bc"
      },
      "source": [
        "model.evaluate([x_test, target_xtest], y_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 32ms/step - loss: 255.0922 - mse: 255.0922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[255.0922088623047, 255.0922088623047]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Pp8UsinhpG"
      },
      "source": [
        "prediction = model.predict([x_test, target_xtest])\n",
        "prediction = np.rint(prediction)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ai-hdEUrMcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac1eba9-03fb-43ed-c87e-578c12e3dd84"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  7.  -8.  -5.   2.]\n",
            " [ 33.  -4.  -5.   5.]\n",
            " [ -6.  -3.  -5.   4.]\n",
            " [ -7.  -4.  -3.   4.]\n",
            " [ 40.  -4.  -3.   7.]\n",
            " [ -2.   2.  -8.   1.]\n",
            " [ 13.  -4.   1.   5.]\n",
            " [  2.  -2.  -6.   5.]\n",
            " [ 37.  -8.   4.   4.]\n",
            " [ 39.   5. -10.   7.]\n",
            " [  0.  -2.  -9.   4.]\n",
            " [ 17.  -3.  -5.  -0.]\n",
            " [ 23.  -0.  -3.  10.]\n",
            " [ -7.  -2.  -3.   3.]\n",
            " [ 26.   8. -14.   9.]\n",
            " [ 15.  -9.  -0.   3.]\n",
            " [ 15.   2. -11.   5.]\n",
            " [ 20.   4. -12.   4.]\n",
            " [ 21.   7.  -8.   8.]\n",
            " [ -6.   2. -12.  10.]\n",
            " [  6.   2. -11.   1.]\n",
            " [ 10.  -4.  -1.   4.]\n",
            " [  5.  -1.  -3.  14.]\n",
            " [-12. -10.  -7.   7.]\n",
            " [ -0.   8. -11.   5.]\n",
            " [ 41.   1.  -5.   4.]\n",
            " [ 29.   6. -10.   9.]\n",
            " [ 38.   4.  -6.   7.]\n",
            " [ 47.  -4.  -3.   5.]\n",
            " [  9.   3.  -8.   6.]\n",
            " [ 32.  -9.   0.  -2.]\n",
            " [ 16.   5. -14.   2.]\n",
            " [ 18. -11.   1.   4.]\n",
            " [ 11.   2.  -8.   0.]\n",
            " [ 49.  -5.  -0.   1.]\n",
            " [ 41.  -7.  -0.   7.]\n",
            " [ 40.  -9.  -4.   8.]\n",
            " [ 31.  -1.  -9.   6.]\n",
            " [ 32.   0. -11.   3.]\n",
            " [ 43.  -0.  -2.   3.]\n",
            " [ 39.  -2.  -4.   5.]\n",
            " [ 27. -11.   2.  12.]\n",
            " [ 54.   1. -10.   3.]\n",
            " [ -1.   6. -10.   2.]\n",
            " [ 37.   1.  -6.   3.]\n",
            " [ 13.  -8.  -2.   2.]\n",
            " [ 33.  -4.  -2.   4.]\n",
            " [ 17.   3.  -3.  11.]\n",
            " [ 10. -13.   2.   6.]\n",
            " [-17.   5.  -9.  13.]\n",
            " [ 20.   1. -13.   5.]\n",
            " [ 11.   1.  -2.   1.]\n",
            " [ 35.  -3.   3.   6.]\n",
            " [ 43. -19.   2.   6.]\n",
            " [ 25.   3.  -6.   4.]\n",
            " [ 33.  -2.  -2.   4.]\n",
            " [ 33.  -5.  -0.   4.]\n",
            " [  2.  -6.   0.   8.]\n",
            " [ 11.   1. -11.   4.]\n",
            " [ 11.  -8.  -2.   4.]\n",
            " [  3.  -2.  -3.  11.]\n",
            " [  6.   3. -16.   6.]\n",
            " [ 18.  -3.  -4.   3.]\n",
            " [ 28.  -1.  -3.   2.]\n",
            " [ 16.  -5.  -1.   6.]\n",
            " [ 35.  -0.  -5.  11.]\n",
            " [ 13.  -2.  -6.   9.]\n",
            " [ 11.   8. -12.   3.]\n",
            " [ 39.  -6.  -3.   4.]\n",
            " [  5.  -6.  -0.   1.]\n",
            " [ -4.   1.  -5.   4.]\n",
            " [  3.  -5.  -5.   4.]\n",
            " [ 29.  14. -18.   7.]\n",
            " [ 18.  -3.  -0.   9.]\n",
            " [ 61.  -3.  -1.   7.]\n",
            " [ 10.  -5.  -4.   6.]\n",
            " [ -0. -11.  -2.   3.]\n",
            " [  5.  -0.  -3.   3.]\n",
            " [ 29.  -1. -15.   4.]\n",
            " [  1.   3.  -8.   7.]\n",
            " [-15.  -2.  -8.  11.]\n",
            " [ 43.  -2.  -2.   4.]\n",
            " [  5. -13.  -2.  12.]\n",
            " [ -1.   5. -14.  13.]\n",
            " [ 10. -12.   1.   5.]\n",
            " [  5.  -2.  -7.  11.]\n",
            " [ 27.  -7.  -0.   8.]\n",
            " [ 31.   4. -11.   1.]\n",
            " [  0.  -0. -10.   4.]\n",
            " [ 26.   5. -15.  10.]\n",
            " [ 17.  -6.  -3.  -2.]\n",
            " [ 35.  -2.  -3.   8.]\n",
            " [ 18.  -3.  -3.   6.]\n",
            " [ 45.  -1.   4.   9.]\n",
            " [  8.   1. -10.  -0.]\n",
            " [ 32.  -6.  -1.   5.]\n",
            " [ 46.  -1.  -0.   9.]\n",
            " [ -3.  -8.  -2.   2.]\n",
            " [ 34.  -8.   1.   5.]\n",
            " [ 26.   7.  -5.   6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCcYNaPzr2fx"
      },
      "source": [
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# img1 = cv2.imread('data65_27.png')\n",
        "# img2 = cv2.imread('target_image_1.png')\n",
        "#mg1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "# img1 = cv2.resize(img1, dsize=(128,128), interpolation = cv2.INTER_CUBIC)\n",
        "# plt.imshow(img1)\n",
        "# img1.shape\n",
        "\n",
        "# img1 = np.expand_dims(img1, axis = 0)\n",
        "# img1 = np.expand_dims(img1, axis = 3)\n",
        "# img1 = img1.astype('float32')\n",
        "# img1 = img1/255\n",
        "# plt.imshow(img1.reshape(128,128), cmap = plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBwNh_ul7Hn"
      },
      "source": [
        "# from PIL import Image\n",
        "# # Open the image form working directory\n",
        "# img1 = Image.open('/content/data65_27.png')\n",
        "# img2 = Image.open('/content/target_image_1.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbJhnxClmnB7"
      },
      "source": [
        "# from matplotlib import image\n",
        "# from matplotlib import pyplot\n",
        "# # load image as pixel array\n",
        "# img1 = image.imread('/content/data65_27.png')\n",
        "# img2 = image.imread('/content/target_image_1.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEwjupKomz2Q"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/data65_27.png')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img= cv2.resize(img, dsize=(128,128), interpolation = cv2.INTER_CUBIC)\n",
        "# plt.imshow(img)\n",
        "img.shape\n",
        "\n",
        "img = np.reshape(img, (1, 128, 128))\n",
        "# img = np.expand_dims(img, axis = 0)\n",
        "# img = np.expand_dims(img, axis = 3)\n",
        "# img = np.reshape(128,128)\n",
        "# img = img.astype('float32')\n",
        "img = img/255\n",
        "img = np.repeat(img[..., np.newaxis], 3, -1)\n",
        "# plt.imshow(img.reshape(128,128), cmap = plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPlFIP9VnWcW"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh3tf8NtpHWw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcDTSZQUm_b2"
      },
      "source": [
        "img2 = cv2.imread('/content/target_image_1.png')\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "img2= cv2.resize(img2, dsize=(128,128), interpolation = cv2.INTER_CUBIC)\n",
        "# plt.imshow(img)\n",
        "img2.shape\n",
        "\n",
        "img2 = np.reshape(img2, (1, 128, 128))\n",
        "# img = np.expand_dims(img, axis = 0)\n",
        "# img = np.expand_dims(img, axis = 3)\n",
        "# img = np.reshape(128,128)\n",
        "# img = img.astype('float32')\n",
        "img2 = img2/255\n",
        "img2 = np.repeat(img2[..., np.newaxis], 3, -1)\n",
        "# plt.imshow(img.reshape(128,128), cmap = plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e7k8WDWpa1c"
      },
      "source": [
        "img2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGxf25z0lUM8"
      },
      "source": [
        "predictionimg = model.predict([img,img2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNAbeatNl20z"
      },
      "source": [
        "predictionimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z38S64ZpeB_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}