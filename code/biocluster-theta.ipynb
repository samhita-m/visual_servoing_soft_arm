{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "error",
     "timestamp": 1624488911306,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "jaGBp0EXyNlj",
    "outputId": "325552a3-1faf-4deb-a84b-e55a43437ce4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir('/home/a-m/marri2/visual_servoing/attempt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1624491457408,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "b5mcsngV9IjX"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import models\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, utils, transforms\n",
    "import re\n",
    "from torch.nn import ReplicationPad3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1624491457651,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "_v7DV_lPf4bq"
   },
   "outputs": [],
   "source": [
    "# global variable\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1624491458457,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "cJak_Tjwf4br"
   },
   "outputs": [],
   "source": [
    "class ImagePoseDataset(Dataset):\n",
    "    \n",
    "    #reading csv file with labels\n",
    "    def __init__(self, image_dir, size = 600, transform=None):\n",
    "        annotation_files = glob.glob(image_dir + '/annotated_*.csv')\n",
    "        \n",
    "        assert len(annotation_files) == 1, \"None or more than one annotation file found at \" + image_dir\n",
    "        self.annotations = pd.read_csv(annotation_files[0])\n",
    "        \n",
    "        self.annotations.astype({'B': 'float32','R': 'float32'}).dtypes  #change this\n",
    "        \n",
    "        self.data = glob.glob(image_dir + '/**/*.jpg', recursive=True)\n",
    "        self.data.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    \n",
    "        \n",
    "        unequal_error = \"Number of images not equal to number of annotations: {} != {}\".format(len(self.data), len(self.annotations[\"image\"].values))\n",
    "        assert len(self.data) == len(self.annotations[\"image\"].values), unequal_error\n",
    "        \n",
    "\n",
    "        # target_scaler = MinMaxScaler()\n",
    "        # target_scaler.fit(y_train)\n",
    "        # y_train = target_scaler.transform(y_train)\n",
    "        # y_test = target_scaler.transform(y_test)\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.image_size = [224, 244] #change this\n",
    "        self.transform = transform\n",
    "        self.size = size\n",
    "        self.minb = self.annotations[\"B\"].values.min()\n",
    "        self.minr = self.annotations[\"R\"].values.min()\n",
    "        self.maxb = self.annotations[\"B\"].values.max()\n",
    "        self.maxr = self.annotations[\"R\"].values.max()\n",
    "        self.pairs = []\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            for j in np.random.choice(range(len(self.data)), size = 1, replace=False):\n",
    "                self.pairs.append((i,j))\n",
    "\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        np.random.seed(230)\n",
    "        \n",
    "        first_img_path = self.data[self.pairs[idx][0]]\n",
    "        second_img_path = self.data[self.pairs[idx][1]]\n",
    "        \n",
    "        img_paths = [first_img_path, second_img_path]\n",
    "        img_name = [os.path.split(img_paths[0])[-1][:-4], os.path.split(img_paths[1])[-1][:-4]]  #might have to change this\n",
    "        images = [Image.open(first_img_path), Image.open(second_img_path)]\n",
    "        \n",
    "        \n",
    "        pose = np.zeros((1, 2), dtype=np.float32)  #change this\n",
    "        annotation1 = self.annotations.loc[self.annotations[\"image\"] == img_name[0]].iloc[0]\n",
    "        annotation2 = self.annotations.loc[self.annotations[\"image\"] == img_name[1]].iloc[0]\n",
    "    \n",
    "        ann1 = annotation1[2:].to_numpy()\n",
    "        ann2 = annotation2[2:].to_numpy()\n",
    "    \n",
    "        pose[0] = ann1 - ann2\n",
    "      #  pose[1] = ann2 - ann1\n",
    "        pose[0][0] = (pose[0][0] - self.minb)/(self.maxb - self.minb)\n",
    "        pose[0][1] = (pose[0][1] - self.minr)/(self.maxr - self.minr)\n",
    "        # print(pose)\n",
    "                \n",
    "        for i in range(len(images)):            \n",
    "            if i == 0:\n",
    "                j = torch.unsqueeze(self.transform(images[i]), dim=0)\n",
    "            else:\n",
    "                k = torch.unsqueeze(self.transform(images[i]), dim=0)\n",
    "                j = torch.cat((j,k), dim=0)\n",
    "        data = j\n",
    "        \n",
    " \n",
    "        sample = {\"images\": data , \"poses\": pose, \"filename\":img_name}        \n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "def fetch_dataloader(types, data_dir, batch_size, num_workers):\n",
    "    \"\"\"\n",
    "    Fetches the DataLoader object for each type in types from data_dir.\n",
    "\n",
    "    Args:\n",
    "        types: (list) has one or more of 'train', 'val', 'test' depending on which data is required\n",
    "        data_dir: (string) directory containing the dataset\n",
    "        params: (Params) hyperparameters\n",
    "\n",
    "    Returns:\n",
    "        data: (dict) contains the DataLoader object for each type in types\n",
    "    \"\"\"\n",
    "    dataloaders = {}\n",
    "    \n",
    "    img_dim = 224\n",
    "\n",
    "    train_transforms = transforms.Compose([transforms.Resize((img_dim, img_dim), Image.BICUBIC),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) \n",
    "    \n",
    "    test_transform = transforms.Compose([transforms.Resize((img_dim, img_dim), Image.BICUBIC),\n",
    "                                         transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) \n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if split in types:\n",
    "            path = os.path.join(data_dir, split)\n",
    "\n",
    "            if split == 'train':\n",
    "                dl = DataLoader(ImagePoseDataset(path, size = 100, transform = train_transforms), \n",
    "                                        batch_size=batch_size, shuffle=False,\n",
    "                                        num_workers=num_workers)\n",
    "\n",
    "            else:\n",
    "                dl = DataLoader(ImagePoseDataset(path, size = 10, transform = test_transform), \n",
    "                                batch_size=batch_size, shuffle=False,\n",
    "                                num_workers=num_workers)\n",
    "\n",
    "            dataloaders[split] = dl\n",
    "\n",
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1624491459134,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "sHCxdUik9Xo8"
   },
   "outputs": [],
   "source": [
    "# data_dir = 'theta-biocluster'\n",
    "# train_dataloader = fetch_dataloader(['train'], data_dir, batch_size=4,num_workers=0)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2855,
     "status": "ok",
     "timestamp": 1624492496654,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "PsombGgzf4bs",
    "outputId": "bb62245b-e644-4a5e-ffd4-f96ce0b81c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4096, 7, 8])\n",
      "torch.Size([2, 2048, 4, 4])\n",
      "torch.Size([2, 1024, 2, 2])\n",
      "torch.Size([2, 512, 1, 1])\n",
      "torch.Size([2, 512, 1, 1])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PoseModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PoseModel, self).__init__()\n",
    "        model1 = models.resnet50(pretrained=True)\n",
    "        model2 = models.resnet50(pretrained=True)\n",
    "        \n",
    "        self.enc1 = nn.Sequential(*list(model1.children())[:-2])\n",
    "        self.enc2 = nn.Sequential(*list(model2.children())[:-2])       \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4096, 2048, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.bn1 = nn.BatchNorm2d(2048)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(2048, 1024, kernel_size=(3,3), stride=(2,2), padding=(1,1))  \n",
    "        self.bn2 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(1024, 512, kernel_size=(3,3), stride=(2,2), padding=(1,1))  \n",
    "        self.bn3 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(512, 256, kernel_size=(3,3), stride=(2,2), padding=(1,1))  \n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.out= nn.Linear(128, 2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, s): \n",
    "        \n",
    "        feature1 = self.enc1(s[:,0])\n",
    "        feature2 = self.enc2(s[:,1])\n",
    "        feature = torch.cat([feature1,feature2],1)\n",
    "        print(feature.shape)\n",
    "        x = F.relu(self.bn1(self.conv1(feature)))\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        print(x.shape)\n",
    "        # x = F.relu(self.bn4(self.conv4(x)))\n",
    "        print(x.shape)\n",
    "        x = torch.reshape(x, (x.size(0),-1))\n",
    "        print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        x = x.view(s.size(0), 1, 2) \n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "net = PoseModel()\n",
    "\n",
    "\n",
    "dummy_input = torch.rand((2, 2, 3, 224, 244))\n",
    "output = net(dummy_input)\n",
    "\n",
    "# print(net)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1624492499716,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "pc7TPnvWf4bw",
    "outputId": "55e788bb-145b-4244-cac9-0b4d4d9cf044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11178.5     0.      0.      0. ]\n"
     ]
    }
   ],
   "source": [
    "class MyCriterion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCriterion, self).__init__()        \n",
    "\n",
    "    def forward(self, prediction, target): \n",
    "            \n",
    "        return F.mse_loss(prediction, target, reduction=\"mean\")\n",
    "    \n",
    "def show_memory():\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0) \n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    f = (r-a)  # free inside reserved\n",
    "    print(np.array([t, r, a, f])/(1024*1024))\n",
    "\n",
    "torch.cuda.empty_cache()        \n",
    "show_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1624492503839,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "_rqob63Qf4bx"
   },
   "outputs": [],
   "source": [
    "def simple_train(model, criterion, optimizer, train_dataloader, **kwargs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    torch.cuda.empty_cache()        \n",
    "    show_memory()\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        img, gt = batch['images'], batch['poses']     \n",
    "        img = img.to(device)\n",
    "        \n",
    "     #   print(img.shape)\n",
    "        gt = gt.to(device)\n",
    "        \n",
    "        img = img.float()\n",
    "        pred = model(img)\n",
    "        print(pred.shape, gt.shape)\n",
    "        \n",
    "        loss = criterion.forward(pred,gt)\n",
    "      \n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        show_memory()\n",
    "        del img\n",
    "        del gt\n",
    "        torch.cuda.empty_cache()        \n",
    "        show_memory()\n",
    "\n",
    "    return sum(losses)/len(losses)\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "def simple_predict(dataloader, model):\n",
    "    model.eval()    \n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            \n",
    "            img, gt = batch['images'], batch['poses']  \n",
    "            img = img.to(device)\n",
    "            gt = gt.to(device)\n",
    "            img = img.float()\n",
    "            \n",
    "            pred = model(img)\n",
    "            # print(pred)\n",
    "\n",
    "            pred = pred.view(-1,3)\n",
    "            gt =  gt.view(-1,3)\n",
    "            \n",
    "            loss = torch.mean(F.mse_loss(pred, gt, reduction=\"none\"),0)\n",
    "            \n",
    "            if i==0:\n",
    "                losses = torch.clone(torch.unsqueeze(loss,0))\n",
    "                \n",
    "            losses = torch.cat([losses,torch.unsqueeze(loss,0)],0)\n",
    "    \n",
    "    losses = torch.mean(losses, 0).cpu().numpy()\n",
    "    b, r, theta = losses[0],losses[1], losses[2]\n",
    "    \n",
    "    \n",
    "\n",
    "    return np.mean(losses),losses[0],losses[1], losses[2], pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 3331,
     "status": "error",
     "timestamp": 1624492507796,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "3hBj-J-Nf4bx",
    "outputId": "3af04533-a2f8-4054-9bc7-54b5e3a95f66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "Epoch 1/50\n",
      "[11178.5          594.           565.40039062    28.59960938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/70 [00:00<00:46,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3394.          2260.14013672  1133.85986328]\n",
      "[11178.5         2314.          2255.54589844    58.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/70 [00:01<00:42,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2320.          2255.54589844    64.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/70 [00:01<00:39,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4/70 [00:02<00:37,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2324.          2255.54589844    68.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5/70 [00:02<00:36,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 6/70 [00:03<00:33,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 7/70 [00:03<00:31,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 8/70 [00:04<00:31,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 9/70 [00:04<00:32,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 11/70 [00:05<00:30,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 12/70 [00:06<00:31,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 13/70 [00:06<00:30,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 14/70 [00:07<00:28,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 15/70 [00:07<00:27,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16/70 [00:08<00:25,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 17/70 [00:08<00:23,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 18/70 [00:09<00:23,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 19/70 [00:09<00:23,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 20/70 [00:09<00:22,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 21/70 [00:10<00:21,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 22/70 [00:10<00:22,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 23/70 [00:11<00:21,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 24/70 [00:11<00:20,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 25/70 [00:12<00:19,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 26/70 [00:12<00:19,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 27/70 [00:13<00:19,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 28/70 [00:13<00:19,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 29/70 [00:14<00:18,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 30/70 [00:14<00:18,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 31/70 [00:15<00:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 32/70 [00:15<00:17,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 34/70 [00:16<00:15,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 35/70 [00:16<00:15,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 36/70 [00:17<00:14,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 37/70 [00:17<00:14,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 38/70 [00:18<00:14,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 39/70 [00:18<00:13,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 40/70 [00:18<00:12,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 41/70 [00:19<00:12,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 42/70 [00:19<00:11,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 43/70 [00:20<00:11,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 44/70 [00:20<00:11,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 45/70 [00:21<00:10,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 46/70 [00:21<00:09,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 48/70 [00:22<00:08,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 49/70 [00:22<00:09,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 50/70 [00:23<00:09,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 51/70 [00:23<00:08,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 52/70 [00:24<00:08,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 53/70 [00:24<00:07,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 54/70 [00:24<00:07,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 55/70 [00:25<00:06,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 56/70 [00:25<00:05,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 57/70 [00:26<00:05,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 58/70 [00:26<00:04,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 59/70 [00:26<00:04,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 60/70 [00:27<00:03,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 61/70 [00:27<00:03,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 62/70 [00:28<00:03,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 63/70 [00:28<00:02,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 64/70 [00:28<00:02,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 65/70 [00:29<00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2324.          2255.54589844    68.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 66/70 [00:29<00:01,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 67/70 [00:29<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 68/70 [00:30<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 69/70 [00:30<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:31<00:00,  2.25it/s]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4096, 7, 7])\n",
      "torch.Size([4, 2048, 4, 4])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 1, 2]) torch.Size([4, 1, 2])\n",
      "[11178.5         3912.          2260.14013672  1651.85986328]\n",
      "[11178.5         2322.          2255.54589844    66.45410156]\n",
      "Training loss 0.22635758950241974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096, 7, 7])\n",
      "torch.Size([1, 2048, 4, 4])\n",
      "torch.Size([1, 1024, 2, 2])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 3]' is invalid for input of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d7fe32d81883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# print(\"Training metrics: b error %.4f, r error %.4f, theta error %.4f, x error %.4f, y error %.4f\" % (train_losses[0],train_losses[1],train_losses[2], train_losses[3], train_losses[4]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-92e32c0eaddd>\u001b[0m in \u001b[0;36msimple_predict\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 3]' is invalid for input of size 2"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "model = PoseModel().to(device)\n",
    "\n",
    "\n",
    "criterion = MyCriterion().to(device)\n",
    "parameter = model.parameters()\n",
    "optimizer = optim.Adam(parameter, lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "# #scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4], gamma=0.1)\n",
    "data_dir = 'data'\n",
    "train_dataloader = fetch_dataloader(['train'], data_dir, batch_size=batch_size,num_workers=0)['train']\n",
    "val_dataloader = fetch_dataloader(['val'], data_dir, batch_size=1,num_workers=0)['val']\n",
    "test_dataloader = fetch_dataloader(['test'], data_dir, batch_size=1,num_workers=0)['test']\n",
    "print(len(train_dataloader))\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "b1 = []\n",
    "r1 = []\n",
    "theta1 = []\n",
    "x1 = []\n",
    "y1 = []\n",
    "\n",
    "predicts = []\n",
    "\n",
    "best_loss = 5000\n",
    "for epoch in range(num_epochs):\n",
    "  \n",
    "    \n",
    "    print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "\n",
    "    epoch_loss = simple_train(model, criterion, optimizer, train_dataloader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    print(\"Training loss {}\".format(epoch_loss))\n",
    "    # print(\"Training metrics: b error %.4f, r error %.4f, theta error %.4f, x error %.4f, y error %.4f\" % (train_losses[0],train_losses[1],train_losses[2], train_losses[3], train_losses[4]))\n",
    "\n",
    "    val_loss, b, r, theta, pred = simple_predict(val_dataloader, model)\n",
    "    b1.append(b)\n",
    "    r1.append(r)\n",
    "    theta1.append(theta)\n",
    "    \n",
    "    predicts.append(pred)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\"Validation loss :\", val_loss)\n",
    "    print(\"Validation metrics: b error %.4f, r error %.4f , theta error %.4f\" % (b, r, theta))\n",
    "\n",
    "    print(\"predictions:\", pred)\n",
    "\n",
    "   \n",
    "    if val_loss<best_loss:          \n",
    "        torch.save(model.state_dict(), 'best_model_theta_outputs.torch')         \n",
    "        best_loss = val_loss\n",
    "        \n",
    "    #scheduler.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1624490362825,
     "user": {
      "displayName": "shivani kamtikar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUMgA00swD3UlAD7Mhraedrk8ZdpRKGd-VzdQ3ZA=s64",
      "userId": "12160226014888825127"
     },
     "user_tz": 300
    },
    "id": "_iIt8iehf4bx"
   },
   "outputs": [],
   "source": [
    "print(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYEMKAeuf4by"
   },
   "outputs": [],
   "source": [
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9B4nrt7IaT7A"
   },
   "outputs": [],
   "source": [
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRlgY2neiAE8"
   },
   "outputs": [],
   "source": [
    "# metrics = predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tR1uUOR8f4by"
   },
   "outputs": [],
   "source": [
    "print([[b1[i],r1[i],theta1[i],x1[i],y1[i]] for i in range(len(b1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAaOu8vBkHpZ"
   },
   "outputs": [],
   "source": [
    "# metrics = np.asarray(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyyLOBhOjEO1"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax1 = plt.subplots()\n",
    "# color = 'tab:red'\n",
    "# ax1.set_xlabel('Epochs')\n",
    "# ax1.set_ylabel('Error (cm)', color=color)\n",
    "# ax1.plot(epochs, metrics[:,0], 'r')\n",
    "# ax1.plot(epochs, metrics[:,1], 'b')\n",
    "# ax1.plot(epochs, metrics[:,2], 'g')\n",
    "# ax1.tick_params(axis='y', labelcolor=color)\n",
    "# ax1.set_ylim(0, 0.1)\n",
    "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "# color = 'tab:blue'\n",
    "# ax2.set_ylabel('Error (radians)', color=color)  # we already handled the x-label with ax1\n",
    "# ax2.plot(epochs, metrics[:,3], 'y')\n",
    "# ax2.plot(epochs, metrics[:,4], 'c')\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZC80mXDgkiKW"
   },
   "outputs": [],
   "source": [
    "# predicts1 = [[71.3455, 299.98846, 612.14197, 17.913647, 67.760956], [70.61943, 308.3565, 614.71674, 18.341103, 66.79955], [72.254776, 308.16354, 624.0446, 17.517784, 68.64179], [79.20256, 313.67682, 756.6699, 21.187294, 76.29698], [68.64581, 445.8373, 1308.4067, 45.08603, 147.08012], [67.010864, 394.3578, 1163.5549, 37.64315, 111.245186], [72.79684, 407.45255, 1438.2988, 37.703526, 122.95048], [66.26516, 509.4921, 2232.0396, 53.581795, 160.51176], [71.617165, 553.7531, 2251.1345, 50.06454, 163.87398], [67.6314, 645.1201, 3004.0298, 64.6395, 201.75027], [68.610435, 670.9459, 3495.046, 70.110756, 229.66035], [78.080925, 838.47186, 3762.1555, 78.345604, 224.2315], [82.31957, 791.64526, 3300.3245, 68.491196, 200.6706], [85.77867, 724.0587, 2986.078, 61.731506, 186.24583], [88.41423, 767.7903, 2660.4978, 58.266937, 180.84425], [92.60425, 729.06586, 2681.3442, 55.219467, 174.54987], [88.064064, 702.8218, 2273.686, 47.222137, 142.69472], [92.22376, 915.272, 3502.126, 67.31765, 197.83511], [95.04986, 732.945, 2337.5552, 47.52399, 143.4624], [103.41726, 750.2705, 1805.5945, 39.52808, 141.29509], [115.16615, 639.1609, 1685.0542, 31.669968, 111.18192], [104.19611, 698.6576, 1724.9683, 36.858562, 113.58083], [112.40713, 964.80774, 2499.877, 51.554733, 155.13557], [95.69072, 626.71136, 1799.6161, 37.875294, 117.63456], [128.13573, 694.4404, 2200.0706, 35.31282, 113.16661], [115.73999, 649.15173, 1381.557, 29.185846, 106.21257], [132.67511, 638.09875, 1506.5328, 31.595715, 90.02608], [140.15654, 648.0216, 1620.7126, 32.83686, 100.44681], [133.61388, 673.5364, 1540.6757, 31.223743, 103.85487], [120.989136, 620.9135, 2077.5657, 36.32834, 108.56132], [132.84982, 589.97534, 1586.4774, 31.332727, 85.892555], [134.00136, 630.5227, 2079.9744, 37.17443, 105.96474], [142.30118, 713.86334, 1812.0747, 34.262226, 93.07108], [131.9562, 618.09344, 1308.4608, 30.623444, 92.09023], [150.78465, 771.7664, 1536.8103, 38.427544, 88.707756], [124.79615, 650.9295, 1969.3282, 37.62735, 109.81103], [117.48657, 528.9835, 1442.0688, 30.423353, 84.737495], [166.30316, 554.52606, 1387.5977, 27.794542, 72.16256], [132.65923, 610.9276, 1272.4724, 30.719393, 83.64812], [170.80846, 651.6129, 1587.1293, 31.822659, 86.05595], [148.26839, 546.7099, 1423.1058, 23.101112, 69.18983], [119.36049, 562.3412, 1525.4735, 33.434387, 90.121826], [126.641014, 579.34705, 1643.3766, 42.385773, 106.71667], [153.49957, 608.18365, 1292.7495, 30.102694, 72.05002], [140.59573, 538.986, 1275.6699, 26.956669, 72.718094], [128.63644, 565.2077, 1283.3916, 31.26406, 80.66515], [142.91138, 589.8891, 1425.4674, 36.772514, 108.61162], [174.99702, 604.99945, 1231.4559, 25.457443, 73.68763], [124.46342, 532.1797, 1284.4299, 37.867233, 90.98839], [156.39485, 572.2624, 1304.4873, 29.487886, 64.113655], [141.00058, 599.98944, 1427.2222, 32.966682, 78.49583], [140.62863, 510.04877, 1460.5568, 28.990866, 70.09744], [122.61561, 541.0749, 1227.1143, 30.144491, 77.38699], [118.877815, 520.6939, 1433.2882, 35.451847, 67.93618], [149.10368, 488.75287, 1207.9657, 27.233482, 74.68739], [114.91516, 574.0989, 1348.9976, 40.59728, 87.81351], [123.55287, 516.64185, 1131.8646, 32.938347, 82.748245], [153.83464, 508.87488, 1146.1227, 26.891317, 54.73151], [140.56522, 608.0974, 1416.4187, 40.215973, 79.94072], [152.53659, 592.6191, 1324.523, 39.891792, 78.46605]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiRofoIskVXO"
   },
   "outputs": [],
   "source": [
    "# predicts1 = np.asarray(predicts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JXZQDtIkQY6"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs = range(1,61)\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# color = 'tab:red'\n",
    "# ax1.set_xlabel('Epochs')\n",
    "# ax1.set_ylabel('Error (cm)', color=color)\n",
    "# ax1.plot(epochs, predicts1[:,0], 'r',)\n",
    "# ax1.plot(epochs, predicts1[:,1], 'b')\n",
    "# ax1.plot(epochs, predicts1[:,2], 'g')\n",
    "# ax1.tick_params(axis='y', labelcolor=color)\n",
    "# # ax1.set_ylim(0, 0.1)\n",
    "\n",
    "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "# color = 'tab:blue'\n",
    "# ax2.set_ylabel('Error (radians)', color=color)  # we already handled the x-label with ax1\n",
    "# ax2.plot(epochs, predicts1[:,3], 'm')\n",
    "# ax2.plot(epochs, predicts1[:,4], 'c')\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "# plt.title('x,y,z,phi,theta,psi error')\n",
    "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXW5C3oHjGov"
   },
   "outputs": [],
   "source": [
    "# epochs = range(1,41)\n",
    "# plt.plot(epochs, train_losses, 'g', label='Training loss')\n",
    "# plt.plot(epochs, val_losses, 'b', label='validation loss')\n",
    "# plt.title('Training and Validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hptcLlnf4b3"
   },
   "outputs": [],
   "source": [
    "# metrics = [[27.24967, 313.78604, 103.22942, 0.12602033, 2.4108167], [27.305887, 312.19617, 103.47133, 0.14717528, 2.3978324], [27.524355, 311.05536, 104.642555, 0.15902913, 2.4331577], [27.548677, 325.57285, 106.00729, 0.13429697, 2.4158552], [27.098442, 328.60037, 104.91552, 0.12587117, 2.472294], [27.359726, 334.21838, 104.05903, 0.12709449, 2.4215572], [27.339266, 358.40887, 106.68851, 0.11997138, 2.393511], [27.588818, 383.73975, 107.74374, 0.11348984, 2.3892288], [27.389458, 371.63693, 105.884705, 0.12097337, 2.403273], [27.360971, 342.81848, 106.109245, 0.11562351, 2.3738363], [27.719664, 393.87692, 110.986465, 0.119660616, 2.3882978], [27.633759, 339.6035, 105.70057, 0.113286234, 2.3775778], [28.07819, 360.8138, 112.83532, 0.11849985, 2.3681376], [28.364185, 360.29456, 117.695984, 0.113442786, 2.388075], [29.205482, 357.27008, 125.467896, 0.11830383, 2.386264], [28.379833, 344.7701, 112.977585, 0.10953671, 2.3661098], [28.847458, 355.65115, 118.61085, 0.111811385, 2.4001744], [27.850155, 341.3711, 114.77934, 0.10915208, 2.3725796], [27.88572, 346.0621, 118.30813, 0.110895686, 2.3910563], [27.872988, 349.0645, 115.55186, 0.10912815, 2.3672535], [28.218578, 353.3147, 131.556, 0.11358704, 2.3951552], [28.392235, 339.58942, 121.12667, 0.111038156, 2.3803837], [28.25236, 329.97418, 115.96446, 0.10942464, 2.3864708], [29.406773, 366.15808, 123.42579, 0.11040557, 2.374963], [29.454271, 344.52792, 131.52682, 0.11232563, 2.3724134], [30.187252, 347.98532, 116.14241, 0.10585186, 2.3729453], [29.41112, 349.68896, 114.18263, 0.10918645, 2.3731532], [28.895391, 348.74268, 113.15022, 0.10991674, 2.3822908], [29.371452, 335.8846, 115.51087, 0.11001146, 2.3862026], [31.134686, 344.45355, 119.50881, 0.108406834, 2.375381], [30.70894, 342.97552, 120.56805, 0.11375582, 2.3945308], [29.832468, 343.45724, 109.87155, 0.10899758, 2.3766632], [29.862116, 343.1723, 113.25473, 0.10866166, 2.3900619], [30.768106, 342.69632, 112.46852, 0.10878944, 2.376799], [31.60865, 343.18985, 121.2012, 0.11096387, 2.392029], [31.704603, 339.0673, 129.9622, 0.109866515, 2.3703597], [29.185385, 334.6232, 109.926186, 0.10787476, 2.377635], [30.564453, 349.78403, 112.91635, 0.10928899, 2.3760023], [30.50954, 335.69626, 113.32439, 0.10892574, 2.3779461], [30.807068, 329.50632, 111.41365, 0.108789176, 2.380784]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xc1SmLUlbKf"
   },
   "outputs": [],
   "source": [
    "# metrics = np.asarray(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tORQA6LLlPAX"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs= range(1, 41)\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# color = 'tab:red'\n",
    "# ax1.set_xlabel('Epochs')\n",
    "# ax1.set_ylabel('Error (cm)', color=color)\n",
    "# ax1.plot(epochs, metrics[:,0], 'r',)\n",
    "# ax1.plot(epochs, metrics[:,1], 'b')\n",
    "# ax1.plot(epochs, metrics[:,2], 'g')\n",
    "# ax1.tick_params(axis='y', labelcolor=color)\n",
    "# # ax1.set_ylim(0, 0.1)\n",
    "\n",
    "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "# color = 'tab:blue'\n",
    "# ax2.set_ylabel('Error (radians)', color=color)  # we already handled the x-label with ax1\n",
    "# ax2.plot(epochs, metrics[:,3], 'm')\n",
    "# ax2.plot(epochs, metrics[:,4], 'c')\n",
    "# # ax2.plot(epochs, metrics[:,5], 'y')\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "# plt.title('x,y,z,phi,theta,psi error')\n",
    "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFcBZhn0lYxk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zwde5I1GyNlw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpM0DK6ByNlw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "biocluster-theta.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
